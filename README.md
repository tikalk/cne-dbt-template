# ğŸš€ Tikal CNE DBT Enterprise Template

[![DBT Version](https://img.shields.io/badge/dbt-1.9.3-FF694B?logo=dbt&logoColor=white)](https://docs.getdbt.com/)
[![Python](https://img.shields.io/badge/Python-3.12+-3776AB?logo=python&logoColor=white)](https://www.python.org/)
[![BigQuery](https://img.shields.io/badge/BigQuery-4285F4?logo=google-cloud&logoColor=white)](https://cloud.google.com/bigquery)
[![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white)](https://www.snowflake.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **Enterprise-grade DBT template with advanced CLI tooling, automated workflows, and production-ready data pipelines**

An opinionated, battle-tested DBT project template designed for enterprise data teams. Features intelligent CLI automation, comprehensive validation, and seamless integration with modern data orchestration platforms like Dagster.

## âœ¨ Key Features

- ğŸ¯ **Smart CLI Interface** - Interactive command-line tools for rapid development
- ğŸ—ï¸ **Enterprise Architecture** - Staging â†’ Marts data modeling patterns  
- ğŸ”„ **Dagster Integration** - Native support for asset-based orchestration
- ğŸ›¡ï¸ **Advanced Validation** - SQL linting, model validation, and data quality checks
- ğŸš€ **CI/CD Ready** - Production-grade GitHub Actions workflows
- ğŸ“Š **Multi-Warehouse Support** - BigQuery, Snowflake, and more
- ğŸ” **Data Observability** - Built-in monitoring with Elementary Data
- ğŸ“ **Auto-Documentation** - Self-documenting models and lineage

## ğŸ¬ Quick Demo

```bash
# Set up your environment in seconds
task setup-env

# Launch the interactive CLI
task cli

# Create a new data domain with models
create domain security_tools --sub-domain crowdstrike
create model --domain security_tools --type staging --name endpoint_data

# Run your pipeline
task dbt:build
```

## ğŸ›ï¸ Architecture Overview

```
ğŸ“ models/
â”œâ”€â”€ ğŸ”§ staging/          # Clean, standardized source data
â”‚   â”œâ”€â”€ integration_tools/
â”‚   â”‚   â”œâ”€â”€ okta/        # Identity & access management
â”‚   â”‚   â”œâ”€â”€ crowdstrike/  # Endpoint security
â”‚   â”‚   â””â”€â”€ active_directory/
â”‚   â””â”€â”€ infra/           # Pipeline metadata & metrics
â””â”€â”€ ğŸª marts/            # Business-ready analytics tables
    â”œâ”€â”€ security/        # Security analytics
    â”œâ”€â”€ compliance/      # Compliance reporting
    â””â”€â”€ operations/      # Operational insights
```

## ğŸš€ Quick Start

### Prerequisites

- [Go-task](https://taskfile.dev/installation/) - Task runner
- Python 3.12+
- Access to BigQuery or Snowflake

### 1. Environment Setup

```bash
# Automated setup (installs gh, uv, pre-commit)
task setup-env

# Or use dev container for containerized development
# (see .devcontainer configuration)
```

### 2. Configuration

```bash
# Copy and configure environment
cp .env_example .env
# Edit .env with your warehouse credentials

# Test your setup
task test-setup
```

### 3. Launch CLI

```bash
# Start interactive CLI with autocomplete
task cli

# Verify warehouse connection
task dbt:debug
```

## ğŸ›ï¸ CLI Commands

Our intelligent CLI provides guided workflows for common tasks:

### ğŸ“Š **Data Modeling**
```bash
create domain <domain_name>              # Create new data domain
create model --domain <name> --type <staging|marts>  # Generate models
create integration-tool <tool_name>      # Add new data source
create macro --name <macro_name>         # Reusable SQL components
```

### ğŸ” **Development & Testing**
```bash
task dbt:run --select <model>           # Run specific models
task dbt:test                           # Execute data tests
task dbt:build                          # Full build pipeline
task dbt:docs                           # Generate documentation
```

### ğŸ› ï¸ **Quality & Validation**
```bash
validate all                            # Run all validations
task dbt:lint                          # SQL formatting
task dbt:format                        # Auto-fix formatting
```

### ğŸ“ˆ **Monitoring & Observability**
```bash
task dbt:edr-report                     # Elementary data report
learn catalog                          # Explore data catalog
select organization                     # Switch contexts
```

## ğŸ—ï¸ Project Structure

### ğŸ“‚ **Models Organization**
```
models/
â”œâ”€â”€ staging/                    # ğŸ§¹ Data cleaning & standardization
â”‚   â”œâ”€â”€ _sources.yml           # Source definitions
â”‚   â””â”€â”€ stg_<source>_<entity>.sql
â”œâ”€â”€ marts/                      # ğŸ¯ Business logic & analytics
â”‚   â”œâ”€â”€ core/                  # Core business entities
â”‚   â”œâ”€â”€ finance/               # Financial analytics
â”‚   â””â”€â”€ security/              # Security metrics
â””â”€â”€ intermediate/              # ğŸ”„ Reusable transformations
```

### ğŸ”§ **Macros & Utilities**
```
macros/
â”œâ”€â”€ create_database/           # Database management
â”œâ”€â”€ generate_schema_name/      # Dynamic schema naming
â”œâ”€â”€ get_custom_alias/          # Table aliasing
â””â”€â”€ normalization/             # Data standardization
```

### ğŸ§ª **Testing & Validation**
- **Generic Tests**: Uniqueness, not-null, referential integrity
- **Singular Tests**: Custom business logic validation
- **Data Quality**: Elementary data monitoring
- **SQL Linting**: SQLFluff integration

## ğŸ”„ CI/CD Pipeline

Our GitHub Actions workflow provides:

- ğŸ” **Slim CI** - Only test changed models
- ğŸ§ª **Automated Testing** - Data quality validation
- ğŸ“Š **Documentation** - Auto-generated data catalog
- ğŸš€ **Deployment** - Multi-environment support
- ğŸ“ˆ **Monitoring** - Performance tracking

### Pipeline Stages
1. **Validation** â†’ SQL linting, model validation
2. **Testing** â†’ Unit tests, data quality checks  
3. **Build** â†’ Compile and run models
4. **Deploy** â†’ Environment-specific deployment
5. **Monitor** â†’ Data freshness and quality alerts

## ğŸ›¡ï¸ Data Quality & Governance

### Built-in Validations
- **Schema Enforcement** - Automatic schema validation
- **Data Freshness** - Source data recency checks
- **Referential Integrity** - Cross-table relationship validation
- **Custom Business Rules** - Domain-specific data quality tests

### Pre-commit Hooks
- ğŸ”’ Security scanning (detect private keys)
- ğŸ“ SQL formatting (SQLFluff)
- ğŸ Python code quality (black, isort, mypy)
- ğŸ§ª DBT validations (parsing, testing)

## ğŸ”§ Configuration

### Environment Variables
```bash
# Warehouse Configuration
SNOWFLAKE_ACCOUNT=your-account
SNOWFLAKE_USER=your-username
SNOWFLAKE_PASSWORD=your-password
SNOWFLAKE_DATABASE=your-database

# BigQuery Configuration  
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
BQ_PROJECT=your-project-id
BQ_DATASET=your-dataset

# Pipeline Configuration
ORG_ID=your-organization-id
DBT_TARGET=dev  # dev, staging, prod
```

### Profiles Configuration
The project supports multiple target environments with automatic schema and database naming conventions.

## ğŸ“š Documentation & Learning

### ğŸ“– **Getting Started Guides**
- [Architecture Overview](docs/overview/11_2_2025_architecture.md)
- [DBT Task Commands](docs/overview/19_2_2025_task_dbt.md)  
- [Main Workflows](docs/overview/19_2_2025_workflow.md)
- [CI/CD Overview](docs/overview/19_2_2025_CI.md)

### ğŸ“ **Recommended Reading**
- [DBT Best Practices](https://docs.getdbt.com/best-practices)
- [DBT and Dagster Integration](https://docs.dagster.io/integrations/dbt)
- [Modern Data Stack Architecture](https://www.getdbt.com/product/what-is-dbt)

### ğŸ”Œ **IDE Extensions**
- [VS Code DBT Power User](https://marketplace.visualstudio.com/items?itemName=innoverio.vscode-dbt-power-user)
- [IntelliJ DBT Plugin](https://plugins.jetbrains.com/plugin/23789-dbt)

## ğŸš¨ Troubleshooting

### Common Issues

**Connection Problems**
```bash
task dbt:debug  # Validate warehouse connection
```

**Model Compilation Errors**
```bash
dbt build --debug  # Verbose logging
# Check compiled SQL in target/compiled/
```

**Performance Issues**
```bash
task dbt:run --select "+state:modified"  # Slim runs
```

### Debug Mode
Enable detailed logging for troubleshooting:
```bash
export DBT_LOG_LEVEL=debug
task dbt:run --debug
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Workflow
1. Fork and clone the repository
2. Create a feature branch
3. Make your changes with tests
4. Run validation: `task validate`
5. Submit a pull request

## ğŸ“Š Monitoring & Observability

### Elementary Data Integration
- **Data Quality Monitoring** - Automated anomaly detection
- **Lineage Tracking** - Visual data flow representation  
- **Performance Metrics** - Query performance insights
- **Alerting** - Slack/email notifications for issues

### Usage Analytics
Track model usage, performance, and data freshness with built-in monitoring dashboards.

## ğŸ¢ Enterprise Features

- **Multi-tenant Architecture** - Organization and instance isolation
- **Role-based Access Control** - Fine-grained permissions
- **Audit Logging** - Complete change tracking
- **Disaster Recovery** - Backup and restore procedures
- **Compliance Ready** - SOX, GDPR, HIPAA support

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details.

## ğŸ™ Acknowledgments

Built with â¤ï¸ by the Tikal CNE team using:
- [DBT](https://www.getdbt.com/) - Data transformation framework
- [Dagster](https://dagster.io/) - Data orchestration platform  
- [Elementary](https://www.elementary-data.com/) - Data observability
- [Go-task](https://taskfile.dev/) - Task automation
- [SQLFluff](https://sqlfluff.com/) - SQL linting

---

**Ready to transform your data pipeline?** ğŸš€ [Get started](#-quick-start) or [explore the docs](#-documentation--learning)!
